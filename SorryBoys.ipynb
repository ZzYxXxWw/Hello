{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOI7wiwqVgpEeJCjwXDBQtn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZzYxXxWw/Hello/blob/main/SorryBoys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIbfN0TVpT3n"
      },
      "outputs": [],
      "source": [
        "# Excerise 1\n",
        "# Hierarchical cluster analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score import seaborn as sns\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage from scipy.spatial.distance import pdist\n",
        "# Load the Iris dataset iris = load_iris()\n",
        "X = iris.data y = iris.target\n",
        "\n",
        "# (a) Identifying the Number of Clusters # Calculate the linkage matrix\n",
        "linkage_matrix = linkage(X, method='ward') # You can choose different linkage methods # Use a dendrogram to identify the number of clusters\n",
        "dendrogram(linkage_matrix) plt.title('Dendrogram') plt.xlabel('Samples') plt.ylabel('Distance') plt.show()\n",
        "# Choose the number of clusters based on dendrogram n_clusters = 3 # Example: 3 clusters\n",
        "# Perform hierarchical clustering\n",
        "hierarchical = AgglomerativeClustering(n_clusters=n_clusters) cluster_memberships = hierarchical.fit_predict(X)\n",
        "# Select two features for the scatter plot (change as needed) feature1 = 0\n",
        "feature2 = 1\n",
        "\n",
        "plt.scatter(X[cluster_memberships == 0, feature1], X[cluster_memberships == 0, feature2], c='red', label='Cluster 1')\n",
        "plt.scatter(X[cluster_memberships == 1, feature1], X[cluster_memberships == 1, feature2], c='blue', label='Cluster 2')\n",
        "plt.scatter(X[cluster_memberships == 2, feature1], X[cluster_memberships == 2, feature2], c='green', label='Cluster 3')\n",
        "plt.xlabel(iris.feature_names[feature1]) plt.ylabel(iris.feature_names[feature2]) plt.legend()\n",
        "\n",
        "plt.title('Scatter Plot of Clustered Objects') plt.show()\n",
        "# (d) Creating a Barplot for Silhouette Coefficients silhouette_avg = silhouette_score(X, cluster_memberships)\n",
        "sample_silhouette_values = silhouette_samples(X, cluster_memberships) sns.barplot(x=sample_silhouette_values, y=range(len(sample_silhouette_values))) plt.xlabel('Silhouette Coefficient')\n",
        "plt.ylabel('Cluster')\n",
        "\n",
        "plt.title(f'Silhouette Coefficients for {n_clusters} Clusters (Avg: {silhouette_avg:.2f})') plt.show()\n"
      ],
      "metadata": {
        "id": "T9VmQMtOpW-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excerise 2\n",
        "# Hierarchical clustering - Dimension reduction"
      ],
      "metadata": {
        "id": "UupEo1XWpkO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as nm\n",
        "\n",
        "import matplotlib.pyplot as mtp\n",
        "\n",
        "import pandas as pd\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('Mall_Customers_data.csv') #training the hierarchical model on dataset\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "hc= AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward') y_pred= hc.fit_predict(x)\n",
        "#visulaizing the clusters\n",
        "mtp.scatter(x[y_pred == 0, 0], x[y_pred == 0, 1], s = 100, c = 'blue', label = 'Cluster 1')\n",
        "mtp.scatter(x[y_pred == 1, 0], x[y_pred == 1, 1], s = 100, c = 'green', label = 'Cluster 2')\n",
        "mtp.scatter(x[y_pred== 2, 0], x[y_pred == 2, 1], s = 100, c = 'red', label = 'Cluster 3')\n",
        "mtp.scatter(x[y_pred == 3, 0], x[y_pred == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')\n",
        "mtp.scatter(x[y_pred == 4, 0], x[y_pred == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5') mtp.title('Clusters of customers')\n",
        "\n",
        "mtp.xlabel('Annual Income (k$)')\n",
        "\n",
        "\n",
        "mtp.ylabel('Spending Score (1-100)') mtp.legend()\n",
        "mtp.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "WOtQaNRHqYtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excerise 3\n",
        "# K-means clustering"
      ],
      "metadata": {
        "id": "Gdi669eJpkLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np import pandas as pd\n",
        "import matplotlib.pyplot as plt import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "%matplotlib inline\n",
        "The necessary libraries are imported.\n",
        "\n",
        "#Reading the excel file data=pd.read_excel(\"Mall_Customers.xlsx\")\n",
        "The data is read. I will share a link to the entire code and excel data at the end of the article.\n",
        "\n",
        "The data has 200 entries, that is data from 200 customers. data.head()\n",
        "#Reading the excel file data=pd.read_excel(\"Mall_Customers.xlsx\")\n",
        "\n",
        "#Distribution of Annnual Income plt.figure(figsize=(10, 6)) sns.set(style = 'whitegrid')\n",
        "sns.distplot(data['Annual Income (k$)']) plt.title('Distribution of Annual Income (k$)', fontsize = 20) plt.xlabel('Range of Annual Income (k$)') plt.ylabel('Count')\n",
        "\n",
        "Distribution of age plt.figure(figsize=(10, 6)) sns.set(style = 'whitegrid') sns.distplot(data['Age'])\n",
        "plt.title('Distribution of Age', fontsize = 20) plt.xlabel('Range of Age') plt.ylabel('Count')\n",
        "\n",
        "\n",
        "#Scatterplot of the input data plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(x = 'Annual Income (k$)',y = 'Spending Score (1-100)', data = X ,s = 60 ) plt.xlabel('Annual Income (k$)')\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.title('Spending Score (1-100) vs Annual Income (k$)') plt.show()\n"
      ],
      "metadata": {
        "id": "GvuuS_-RqhP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excerise 4\n",
        "# k- Means clustering for a synthetic data set"
      ],
      "metadata": {
        "id": "piQ_4burpkIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "# Generate synthetic data with 3 clusters np.random.seed(0)\n",
        "data = np.concatenate([np.random.randn(100, 2), 5 + np.random.randn(100, 2), 10 +\n",
        "np.random.randn(100, 2])\n",
        "# Number of clusters n_clusters = 3\n",
        "# Number of K-means cycles n_cycles = 3\n",
        "for cycle in range(n_cycles):\n",
        "\n",
        "# Initialize K-means clustering\n",
        "\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "# Fit the model kmeans.fit(data)\n",
        "# Get cluster centers and labels cluster_centers = kmeans.cluster_centers_\n",
        "labels = kmeans.labels_\n",
        "# Visualize the clusters\n",
        "\n",
        "plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis')\n",
        "\n",
        "plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], s=200, c='red') plt.title(f'K-means Clustering - Cycle {cycle + 1}')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "edBjm_6-qv_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excerise 5\n",
        "# K Means - elbow method"
      ],
      "metadata": {
        "id": "O3Nke8oxpkGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "data = list(zip(x, y)) inertias = []\n",
        "\n",
        "for i in range(1,11):\n",
        "kmeans = KMeans(n_clusters=i) kmeans.fit(data) inertias.append(kmeans.inertia_)\n",
        "x = [4, 5, 10, 4, 3, 11, 14 , 6, 10, 12]\n",
        "y = [21, 19, 24, 17, 16, 25, 24, 22, 21, 21]\n",
        "\n",
        "data = list(zip(x, y))\n",
        "print(data)\n",
        "plt.plot(range(1,11), inertias, marker='o') plt.title('Elbow method') plt.xlabel('Number of clusters') plt.ylabel('Inertia')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4lgQbh4bq3DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excerise 6\n",
        "# k-medoids clustering"
      ],
      "metadata": {
        "id": "21qYhbilpkDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "\n",
        "\n",
        "# Generate synthetic data with 3 clusters np.random.seed(0)\n",
        "data = np.concatenate([np.random.randn(100, 2), 5 + np.random.randn(100, 2), 10 +\n",
        "np.random.randn(100, 2)])\n",
        "\n",
        "\n",
        "# Number of clusters n_clusters = 3\n",
        "\n",
        "# Number of K-medoids cycles n_cycles = 3\n",
        "\n",
        "for cycle in range(n_cycles):\n",
        "\n",
        "# Initialize K-medoids clustering\n",
        "\n",
        "kmedoids = KMedoids(n_clusters=n_clusters, random_state=0)\n",
        "# Fit the model kmedoids.fit(data)\n",
        "# Get cluster medoids and labels cluster_medoids = kmedoids.cluster_centers_\n",
        "labels = kmedoids.labels_ # Visualize the clusters\n",
        "plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis')\n",
        "\n",
        "plt.scatter(cluster_medoids[:, 0], cluster_medoids[:, 1], s=200, c='red') plt.title(f'K-medoids Clustering - Cycle {cycle + 1}')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pqWtwEMJq-YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excerise 7\n",
        "# k-medoids clustering using sklearn"
      ],
      "metadata": {
        "id": "9G8TVWQcpkAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn_extra.cluster import KMedoids from sklearn.metrics import silhouette_score # Generate synthetic data with 3 clusters np.random.seed(0)\n",
        "data = np.concatenate([np.random.randn(100, 2), 5 + np.random.randn(100, 2), 10 +\n",
        "np.random.randn(100, 2)]) # Number of clusters n_clusters = 3\n",
        "# Initialize K-medoids clustering\n",
        "\n",
        "kmedoids = KMedoids(n_clusters=n_clusters, random_state=0)\n",
        "\n",
        "\n",
        "# Fit the model kmedoids.fit(data)\n",
        "\n",
        "# Get cluster medoids and labels cluster_medoids = kmedoids.cluster_centers_ labels = kmedoids.labels_\n",
        "# Calculate the silhouette score silhouette_avg = silhouette_score(data, labels) print(f\"Silhouette Score: {silhouette_avg}\")\n",
        "\n",
        "# Visualize the clusters\n",
        "\n",
        "plt.scatter(data[:, 0], data[:, 1], c=labels, cmap='viridis')\n",
        "\n",
        "plt.scatter(cluster_medoids[:, 0], cluster_medoids[:, 1], s=200, c='red') plt.title('K-medoids Clustering')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kZ0eSiNZrC-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excerise 8\n",
        "# knn clustering"
      ],
      "metadata": {
        "id": "Q1vtgahdpj-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from sklearn.metrics import silhouette_score # Load the digits dataset\n",
        "digits = datasets.load_digits() data = digits.data\n",
        "# Define a range of k values to test\n",
        "\n",
        "k_values = range(2, 11) # You can adjust this range # Initialize lists to store silhouette scores silhouette_scores = []\n",
        "for k in k_values:\n",
        "\n",
        "# Initialize K-means clustering\n",
        "\n",
        "kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "\n",
        "# Fit the model kmeans.fit(data)\n",
        "# Get cluster labels labels = kmeans.labels_\n",
        "# Calculate the silhouette score\n",
        "\n",
        "silhouette = silhouette_score(data, labels) silhouette_scores.append(silhouette\n",
        "# Plot the silhouette scores for different k values plt.plot(k_values, silhouette_scores, marker='o') plt.xlabel('Number of Clusters (k)') plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score for Different k Values') plt.show()\n"
      ],
      "metadata": {
        "id": "5FlYGEOvrM8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excerise 9\n",
        "# Naive Bayes classification"
      ],
      "metadata": {
        "id": "OYGgm_a0pj7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.model_selection import train_test_split from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset data = load_iris()\n",
        "X = data.data y = data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "# Naïve Bayes Classification naive_bayes_classifier = GaussianNB()\n",
        "\n",
        "naive_bayes_classifier.fit(X_train, y_train) y_nb_pred = naive_bayes_classifier.predict(X_test) accuracy_nb = accuracy_score(y_test, y_nb_pred) print(f'Naïve Bayes Accuracy: {accuracy_nb:.2f}')\n",
        "\n",
        "# K-nearest Neighbors (KNN) Classification knn_classifier = KNeighborsClassifier(n_neighbors=3) knn_classifier.fit(X_train, y_train)\n",
        "y_knn_pred = knn_classifier.predict(X_test) accuracy_knn = accuracy_score(y_test, y_knn_pred) print(f'KNN Accuracy: {accuracy_knn:.2f}')\n"
      ],
      "metadata": {
        "id": "BQ3WmznorUYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excerise 10\n",
        "# Decision tree Classifier"
      ],
      "metadata": {
        "id": "toinqgzqpj4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.model_selection import train_test_split from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset data = load_iris()\n",
        "X = data.data y = data.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Decision Tree Classifier\n",
        "\n",
        "decision_tree_classifier = DecisionTreeClassifier() decision_tree_classifier.fit(X_train, y_train) y_dt_pred = decision_tree_classifier.predict(X_test) accuracy_dt = accuracy_score(y_test, y_dt_pred) print(f'Decision Tree Accuracy: {accuracy_dt:.2f}')\n",
        "\n",
        "# Linear Discriminant Analysis (LDA) Classifier lda_classifier = LinearDiscriminantAnalysis() lda_classifier.fit(X_train, y_train)\n",
        "y_lda_pred = lda_classifier.predict(X_test) accuracy_lda = accuracy_score(y_test, y_lda_pred) print(f'LDA Accuracy: {accuracy_lda:.2f}')\n"
      ],
      "metadata": {
        "id": "rp1VDuD3ra2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excerise 11\n",
        "# Comparing the performances of knn, decision tree, logistic regression"
      ],
      "metadata": {
        "id": "Co_EAbNIpj2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer from sklearn.model_selection import train_test_split from sklearn.neighbors import KNeighborsClassifier from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score\n",
        "# Load the Breast Cancer dataset data = load_breast_cancer()\n",
        "X = data.data y = data.target\n",
        "# Split the data into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) # K-nearest Neighbors (KNN) Classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5) # You can adjust the number of neighbors\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "y_knn_pred = knn_classifier.predict(X_test) accuracy_knn = accuracy_score(y_test, y_knn_pred) print(f'KNN Accuracy: {accuracy_knn:.2f}')\n",
        "\n",
        "# Decision Tree Classifier\n",
        "\n",
        "decision_tree_classifier = DecisionTreeClassifier() decision_tree_classifier.fit(X_train, y_train) y_dt_pred = decision_tree_classifier.predict(X_test) accuracy_dt = accuracy_score(y_test, y_dt_pred) print(f'Decision Tree Accuracy: {accuracy_dt:.2f}')\n",
        "\n",
        "# Logistic Regression Classifier\n",
        "\n",
        "logistic_regression_classifier = LogisticRegression(max_iter=10000) logistic_regression_classifier.fit(X_train, y_train)\n",
        "y_lr_pred = logistic_regression_classifier.predict(X_test) accuracy_lr = accuracy_score(y_test, y_lr_pred) print(f'Logistic Regression Accuracy: {accuracy_lr:.2f}')\n"
      ],
      "metadata": {
        "id": "k0ScxHrLrh6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excerise 12\n",
        "# SVM Classifier"
      ],
      "metadata": {
        "id": "ZTYTFE3_pjzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cacer\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score\n",
        "# Load the Breast Cancer dataset data = load_breast_cancer()\n",
        "X = data.data y = data.target\n",
        "# Split the data into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "# Support Vector Machine (SVM) with Hyperparameter Tuning svm_params = {\n",
        "'C': [0.1, 1, 10], # Regularization parameter 'kernel': ['linear', 'rbf'], # Kernel type\n",
        "\n",
        "}\n",
        "\n",
        "svm_classifier = SVC()\n",
        "\n",
        "svm_grid = GridSearchCV(svm_classifier, svm_params, cv=5) svm_grid.fit(X_train, y_train)\n",
        "best_svm = svm_grid.best_estimator_ y_svm_pred = best_svm.predict(X_test)\n",
        "accuracy_svm = accuracy_score(y_test, y_svm_pred) print(f'SVM Accuracy: {accuracy_svm:.2f}')\n",
        "# Logistic Regression Classifier\n",
        "logistic_regression_classifier = LogisticRegression(max_iter=10000) logistic_regression_classifier.fit(X_train, y_train)\n",
        "y_lr_pred = logistic_regression_classifier.predict(X_test) accuracy_lr = accuracy_score(y_test, y_lr_pred) print(f'Logistic Regression Accuracy: {accuracy_lr:.2f}')\n"
      ],
      "metadata": {
        "id": "Q3RL_9D3roDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excerise 13\n",
        "# Hyper-parameter tuning of SVM"
      ],
      "metadata": {
        "id": "CYs8HxsHpjw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# Load the Digits dataset digits = load_digits()\n",
        "X = digits.data y = digits.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "# Define the hyperparameter grid for the SVM param_grid = {\n",
        "'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'],'gamma': [0.001, 0.01, 0.1]}\n",
        "\n",
        "# Create an SVM classifier svm_classifier = SVC()\n",
        "# Perform hyperparameter tuning using GridSearchCV grid_search = GridSearchCV(svm_classifier, param_grid, cv=5) grid_search.fit(X_train, y_train)\n",
        "best_svm = grid_search.best_estimator_ # Make predictions on the test data y_pred = best_svm.predict(X_test)\n",
        "# Generate a classification report\n",
        "\n",
        "report = classification_report(y_test, y_pred) print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "RiW_hg32rt6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Excerise 14\n",
        "# SVM in novelty detection and regression"
      ],
      "metadata": {
        "id": "gBYWUbmopjut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Generating some example data np.random.seed(42)\n",
        "X_train = np.sort(5 * np.random.rand(40, 1), axis=0) y_train = np.sin(X_train).ravel()\n",
        "\n",
        "# Adding some outliers for novelty detection outliers_fraction = 0.05\n",
        "X_outliers = 5 * np.random.rand(20, 1)\n",
        "y_outliers = 3 * np.random.randn(20, 1) X_train = np.vstack([X_train, X_outliers])\n",
        "y_train = np.concatenate([y_train, y_outliers[:, 0]])\n",
        "\n",
        "# Novelty Detection using One-Class SVM\n",
        "clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1) clf.fit(X_train)\n",
        "\n",
        "# Regression using SVM\n",
        "regr = svm.SVR(kernel='linear', C=100) regr.fit(X_train, y_train)\n",
        "\n",
        "# Plotting the results\n",
        "plt.scatter(X_train, y_train, color='black', label='data') plt.scatter(X_outliers, y_outliers, color='red', label='outliers')\n",
        "plt.plot(X_train, clf.decision_function(X_train), color='blue', label='novelty score') plt.plot(X_train, regr.predict(X_train), color='green', label='SVR')\n",
        "\n",
        "plt.legend() plt.show()\n"
      ],
      "metadata": {
        "id": "K5gdQ91epjKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extra Program"
      ],
      "metadata": {
        "id": "GSk4VFVvsDKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ex: 1\n",
        "The below CSV file contains different person name, gender, and age saved as ‘biostats.csv’:\n",
        "\n",
        "The approach of the program:\n",
        "1.\tImport required libraries, matplotlib library for visualizing, and CSV library for reading CSV data.\n",
        "2.\tOpen the file using open( ) function with ‘r’ mode (read-only) from CSV library and read the file using csv.reader( ) function.\n",
        "3.\tRead each line in the file using for loop.\n",
        "4.\tAppend required columns into a list.\n",
        "5.\tAfter reading the whole CSV file, plot the required data as X and Y axis.\n",
        "6.\tIn this example, we are plotting names as X-axis and ages as Y-axis.\n",
        "\n",
        "Code:\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "with open('biostats.csv','r') as csvfile:\n",
        "\tplots = csv.reader(csvfile, delimiter = ',')\n",
        "\n",
        "\tfor row in plots:\n",
        "\t\tx.append(row[0])\n",
        "\t\ty.append(int(row[2]))\n",
        "\n",
        "plt.bar(x, y, color = 'g', width = 0.72, label = \"Age\")\n",
        "plt.xlabel('Names')\n",
        "plt.ylabel('Ages')\n",
        "plt.title('Ages of different persons')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Ex : 2\n",
        "\n",
        "Temperature(°C) on different dates is stored in a CSV file as ‘Weatherdata.csv’. These two rows ‘Dates’ and ‘Temperature(°C )’ are used as X and Y-axis for visualizing weather reports.\n",
        "\n",
        "\n",
        "\n",
        "Approach of the program:\n",
        "1.\tImport required libraries, matplotlib library for visualizing, and csv library for reading CSV data.\n",
        "2.\tOpen the file using open( )  function with ‘r’ mode (read-only) from CSV library and read the file using csv.reader( ) function.\n",
        "3.\tRead each line in the file using for loop.\n",
        "4.\tAppend required columns of the CSV file into a list.\n",
        "5.\tAfter reading the whole CSV file, plot the required data as X and Y axis.\n",
        "6.\tIn this Example, we are plotting Dates as X-axis and Temperature(°C ) as Y-axis.\n",
        "\n",
        "Code:\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "with open('Weatherdata.csv','r') as csvfile:\n",
        "\tlines = csv.reader(csvfile, delimiter=',')\n",
        "\tfor row in lines:\n",
        "\t\tx.append(row[0])\n",
        "\t\ty.append(int(row[1]))\n",
        "\n",
        "plt.plot(x, y, color = 'g', linestyle = 'dashed',\n",
        "\t\tmarker = 'o',label = \"Weather Data\")\n",
        "\n",
        "plt.xticks(rotation = 25)\n",
        "plt.xlabel('Dates')\n",
        "plt.ylabel('Temperature(°C)')\n",
        "plt.title('Weather Report', fontsize = 20)\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MGMBsCirsBHP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}